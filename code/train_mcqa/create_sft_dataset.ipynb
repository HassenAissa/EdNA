{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ff05724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46605b1f",
   "metadata": {},
   "source": [
    "# unsloth/OpenMathReasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2621c93",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'source'],\n",
       "    num_rows: 192523\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_dataset_hf = load_dataset(\"unsloth/OpenMathReasoning\", split=\"cot\")\n",
    "reasoning_dataset_hf = reasoning_dataset_hf.remove_columns(\n",
    "    [col for col in reasoning_dataset_hf.column_names if col not in [\"problem\", \"generated_solution\"]]\n",
    ")\n",
    "def prepare_reasoning_dataset_hf(example):\n",
    "    with open(\"open_qsts_prompts.json\", \"r\") as f:\n",
    "        prompts = json.load(f)\n",
    "    prompt = random.choice(prompts)\n",
    "    return {\n",
    "        \"question\": prompt.replace(\"<question>\", example[\"problem\"]),\n",
    "        \"answer\": example[\"generated_solution\"],\n",
    "        \"source\": \"unsloth/OpenMathReasoning\",\n",
    "    }\n",
    "\n",
    "reasoning_dataset_hf = reasoning_dataset_hf.map(prepare_reasoning_dataset_hf, remove_columns=[\"problem\", \"generated_solution\"])\n",
    "reasoning_dataset_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de904380",
   "metadata": {},
   "source": [
    "# Finetome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49260ad9",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'question', 'answer'],\n",
       "    num_rows: 77831\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_data = load_dataset(\"mlabonne/FineTome-100k\")[\"train\"]\n",
    "conversational_data = conversational_data.filter(lambda x: len(x[\"conversations\"]) == 2)\n",
    "def clean_conversational_data(example):\n",
    "    question = example[\"conversations\"][0][\"value\"]\n",
    "    answer = example[\"conversations\"][1][\"value\"]\n",
    "    return {\n",
    "        \"source\": \"mlabonne/FineTome-100k\",\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    "\n",
    "conversational_data = conversational_data.map(clean_conversational_data, remove_columns=conversational_data.column_names)\n",
    "conversational_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0195b62b",
   "metadata": {},
   "source": [
    "# TULU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f8ee3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tulu_dataset_math = load_dataset(\"allenai/tulu-3-sft-personas-math\")[\"train\"]\n",
    "tulu_dataset_code = load_dataset(\"allenai/tulu-3-sft-personas-code\")[\"train\"]\n",
    "tulu_dataset_algebra = load_dataset(\"allenai/tulu-3-sft-personas-algebra\")[\"train\"]\n",
    "tulu_dataset_math_grade = load_dataset(\"allenai/tulu-3-sft-personas-math-grade\")[\"train\"]\n",
    "\n",
    "def clean_tulu_data(example):\n",
    "    question = example[\"messages\"][0][\"content\"]\n",
    "    answer = example[\"messages\"][1][\"content\"]\n",
    "    return {\n",
    "        \"source\": \"allenai/tulu-3-sft-mixture\",\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    "\n",
    "tulu_dataset_math = tulu_dataset_math.map(clean_tulu_data, remove_columns=tulu_dataset_math.column_names)\n",
    "tulu_dataset_code = tulu_dataset_code.map(clean_tulu_data, remove_columns=tulu_dataset_code.column_names)\n",
    "tulu_dataset_algebra = tulu_dataset_algebra.map(clean_tulu_data, remove_columns=tulu_dataset_algebra.column_names)\n",
    "tulu_dataset_math_grade = tulu_dataset_math_grade.map(clean_tulu_data, remove_columns=tulu_dataset_math_grade.column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2bce55",
   "metadata": {},
   "source": [
    "# MCQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72105ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608e18e95b344dfcbdb73b1166b8a003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d572139b7324e3c843fde820a563b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/149M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3352671bf38540d48afef863b39efffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/775k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc5d8a16c9a41f692c9d489bf1839be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/6.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e22b5b3f0741a99af808ab3844a940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/331322 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830282ff87aa4964ae1137d5eca1e03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5280 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c6d14249624c819ebc8f578e962960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/19388 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697cdbdf39e841ce9880edc8f58a2dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/331322 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356bc0f97f674af0843dd0f8bd807ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/233855 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'source'],\n",
       "    num_rows: 233855\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq_dataset = load_dataset(\"HAissa/MCQ_dataset\")[\"train\"]\n",
    "mcq_dataset = mcq_dataset.filter(lambda x: x[\"source\"] != \"deepmind/aqua_rat\")\n",
    "def add_mcq_prompts(example):\n",
    "    question = example[\"question\"]\n",
    "    answer = example[\"answer\"]\n",
    "    question = question.replace(\"\\nA)\", \"\\nA.\")\n",
    "    question = question.replace(\"\\nB)\", \"\\nB.\")\n",
    "    question = question.replace(\"\\nC)\", \"\\nC.\")\n",
    "    question = question.replace(\"\\nD)\", \"\\nD.\")\n",
    "    question = question.replace(\"\\nE)\", \"\\nE.\")\n",
    "    answer = answer.replace(\"A)\", \"A.\")\n",
    "    answer = answer.replace(\"B)\", \"B.\")\n",
    "    answer = answer.replace(\"C)\", \"C.\")\n",
    "    answer = answer.replace(\"D)\", \"D.\")\n",
    "    answer = answer.replace(\"E)\", \"E.\")\n",
    "    return {\n",
    "        \"source\": example[\"source\"],\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    "mcq_dataset = mcq_dataset.map(add_mcq_prompts, remove_columns=mcq_dataset.column_names)\n",
    "mcq_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9f7950",
   "metadata": {},
   "source": [
    "# aquarat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f64fdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Two friends plan to walk along a 43-km trail, starting at opposite ends of the trail at the same time. If Friend P's rate is 15% faster than Friend Q's, how many kilometers will Friend P have walked when they pass each other?\\nA.21\\nB.21.5\\nC.22\\nD.22.5\\nE.23\",\n",
       " 'source': 'deepmind/aqua_rat',\n",
       " 'answer': 'E.23\\nExplanation: If Q complete x kilometers, then P completes 1.15x kilometers.\\nx + 1.15x = 43\\n2.15x=43\\nx = 43/2.15 = 20\\nThen P will have have walked 1.15*20=23 km.\\nThe answer is E.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqua_dataset = load_dataset(\"deepmind/aqua_rat\")[\"train\"]\n",
    "def prepare_aqua_data(example):\n",
    "    options = example[\"options\"]\n",
    "    question = example[\"question\"]\n",
    "    rationale = example[\"rationale\"]\n",
    "    correct_answer = example[\"correct\"]\n",
    "    for choice in options:\n",
    "        question+= f\"\\n{choice}\"\n",
    "    question = question.replace(\"\\nA)\", \"\\nA.\")\n",
    "    question = question.replace(\"\\nB)\", \"\\nB.\")\n",
    "    question = question.replace(\"\\nC)\", \"\\nC.\")\n",
    "    question = question.replace(\"\\nD)\", \"\\nD.\")\n",
    "    question = question.replace(\"\\nE)\", \"\\nE.\")\n",
    "    answer_value = options[ord(correct_answer) - ord('A')]\n",
    "    answer_value = answer_value.replace(\"A)\", \"A.\")\n",
    "    answer_value = answer_value.replace(\"B)\", \"B.\")\n",
    "    answer_value = answer_value.replace(\"C)\", \"C.\")\n",
    "    answer_value = answer_value.replace(\"D)\", \"D.\")\n",
    "    answer_value = answer_value.replace(\"E)\", \"E.\")\n",
    "    correct_answer = f\"{answer_value}\\nExplanation: {rationale}\"\n",
    "    return {\n",
    "        \"source\": \"deepmind/aqua_rat\",\n",
    "        \"question\": question,\n",
    "        \"answer\": correct_answer,\n",
    "    }\n",
    "\n",
    "aqua_dataset = aqua_dataset.map(prepare_aqua_data, remove_columns=aqua_dataset.column_names)\n",
    "aqua_dataset[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff8098",
   "metadata": {},
   "source": [
    "# GSM8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54809b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm8k = load_dataset(\"openai/gsm8k\", \"main\")[\"train\"]\n",
    "def prepare_gsm8k_data(example):\n",
    "    question = example[\"question\"]\n",
    "    answer = example[\"answer\"]\n",
    "    return {\n",
    "        \"source\": \"cais/gsm8k\",\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    "\n",
    "gsm8k = gsm8k.map(prepare_gsm8k_data, remove_columns=gsm8k.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24833c4",
   "metadata": {},
   "source": [
    "# stack math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffc386e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_math = load_dataset(\"math-ai/StackMathQA\", \"stackmathqa400k\")[\"train\"]\n",
    "def prepare_stack_math_data(example):\n",
    "    question = example[\"Q\"]\n",
    "    answer = example[\"A\"]\n",
    "    return {\n",
    "        \"source\": \"math-ai/StackMathQA\",\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    "\n",
    "stack_math = stack_math.map(prepare_stack_math_data, remove_columns=stack_math.column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20080506",
   "metadata": {},
   "source": [
    "# Combine all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0d205a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'question', 'answer'],\n",
       "    num_rows: 1186257\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train_dataset = concatenate_datasets([\n",
    "    tulu_dataset_math,\n",
    "    tulu_dataset_code,\n",
    "    tulu_dataset_algebra,\n",
    "    tulu_dataset_math_grade,\n",
    "    mcq_dataset,\n",
    "    aqua_dataset,\n",
    "    gsm8k,\n",
    "    stack_math,\n",
    "    reasoning_dataset_hf\n",
    "])\n",
    "\n",
    "combined_train_dataset = combined_train_dataset.shuffle(seed=42)\n",
    "combined_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2b3a387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'question', 'answer'],\n",
       "        num_rows: 1186257\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answer', 'source'],\n",
       "        num_rows: 5280\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'source'],\n",
       "        num_rows: 19388\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = load_dataset(\"HAissa/MCQ_dataset\")[\"validation\"]\n",
    "test = load_dataset(\"HAissa/MCQ_dataset\")[\"test\"]\n",
    "total_dataset = DatasetDict({\n",
    "    \"train\": combined_train_dataset,\n",
    "    \"validation\": validation,\n",
    "    \"test\": test\n",
    "})\n",
    "total_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbced424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c14fc10b044c8fab45b73027c3ec00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5deca1616b9448d9eb94c29e0e8475a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/149 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965392af63074ffc8b023c510387b5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/149 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74526c210d34c9cb021b7c2fe82dd30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/149 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb46e733b0bb4e8c8ab7640f4fa64eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/149 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaefe5f3f98342bfae9ac10a0b5a2c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/149 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ded4ae05834246a7dd32ee3c6fdf34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/149 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de94062f4e0143eb89ec61a5d0439a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/149 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ef8ec77ff14425867206ab4cda5877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/149 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95153143fef47d8938585a64f914b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5e8263ac6b4c4cadbc2c2114ec9e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5797251f6c7747019371474578e7454d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30abea4bbc54d90ab56ba2f57822d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/HAissa/MNLP_M3_mcqa_dataset/commit/66de2783860a41fd71277b4d04e834c83d866ab7', commit_message='Upload dataset', commit_description='', oid='66de2783860a41fd71277b4d04e834c83d866ab7', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/HAissa/MNLP_M3_mcqa_dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='HAissa/MNLP_M3_mcqa_dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset.push_to_hub(\"HAissa/MNLP_M3_mcqa_dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
