{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3bd2a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, DatasetDict, Dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c1f8d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_choice(choice):\n",
    "    choice = choice.replace(\"A)\", \"A.\").replace(\"B)\", \"B.\").replace(\"C)\", \"C.\").replace(\"D)\", \"D.\").replace(\"E)\", \"E.\")\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce45ca8a",
   "metadata": {},
   "source": [
    "# aquarat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "40e52b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c8cc8407c14bcc9b5b4b843ada566f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/97467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aquarat = load_dataset(\"deepmind/aqua_rat\")\n",
    "aquarat_validation = aquarat[\"validation\"]\n",
    "aquarat_train = aquarat[\"train\"]\n",
    "aquarat_test = aquarat[\"test\"]\n",
    "def create_questions(question, options, correct_answer):\n",
    "    formatted_question = question\n",
    "    for i, option in enumerate(options):\n",
    "        option = format_choice(option)\n",
    "        formatted_question += f\"\\n{option}\"\n",
    "    \n",
    "\n",
    "    index = ord(correct_answer) - ord(\"A\")\n",
    "    answer_text = options[index]\n",
    "    answer_text = format_choice(answer_text)\n",
    "    return formatted_question, answer_text\n",
    "\n",
    "aquarat_validation = aquarat_validation.map(\n",
    "    lambda x: {\n",
    "        \"question\": create_questions(x[\"question\"], x[\"options\"], x[\"correct\"])[0],\n",
    "        \"answer\": create_questions(x[\"question\"], x[\"options\"], x[\"correct\"])[1],\n",
    "        \"source\": \"deepmind/aqua_rat\",\n",
    "    },\n",
    "    remove_columns=aquarat_validation.column_names,\n",
    ")\n",
    "\n",
    "aquarat_test = aquarat_test.map(\n",
    "    lambda x: {\n",
    "        \"question\": create_questions(x[\"question\"], x[\"options\"], x[\"correct\"])[0],\n",
    "        \"answer\": create_questions(x[\"question\"], x[\"options\"], x[\"correct\"])[1],\n",
    "        \"source\": \"deepmind/aqua_rat\",\n",
    "    },\n",
    "    remove_columns=aquarat_test.column_names,\n",
    ")\n",
    "aquarat_train = aquarat_train.map(\n",
    "    lambda x: { \n",
    "        \"question\": create_questions(x[\"question\"], x[\"options\"], x[\"correct\"])[0],\n",
    "        \"answer\": create_questions(x[\"question\"], x[\"options\"], x[\"correct\"])[1],\n",
    "        \"source\": \"deepmind/aqua_rat\",\n",
    "    },\n",
    "    remove_columns=aquarat_train.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759bbf04",
   "metadata": {},
   "source": [
    "# Arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1a303e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95cb729ba6249399d8833210ca4ee72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arc_chal_val = load_dataset(\"allenai/ai2_arc\", \"ARC-Challenge\")[\"validation\"]\n",
    "arc_chal_test = load_dataset(\"allenai/ai2_arc\", \"ARC-Challenge\")[\"test\"]\n",
    "arc_easy_val = load_dataset(\"allenai/ai2_arc\", \"ARC-Easy\")[\"validation\"]\n",
    "arc_eady_test = load_dataset(\"allenai/ai2_arc\", \"ARC-Easy\")[\"test\"]\n",
    "arc_chal_train = load_dataset(\"allenai/ai2_arc\", \"ARC-Challenge\")[\"train\"]\n",
    "def create_questions(question, options, answer_letter):\n",
    "    formatted_question = question\n",
    "    for i, option in enumerate(options[\"text\"]):\n",
    "        formatted_question += f\"\\n{chr(65 + i)}. {option}\"\n",
    "    \n",
    "    # Get the correct answer option (A, B, C, etc.)\n",
    "    answers = options[\"label\"]\n",
    "    index = answers.index(answer_letter)\n",
    "    answer_text = f\"{answer_letter}. {options['text'][index]}\"\n",
    "    \n",
    "    return formatted_question, answer_text\n",
    "\n",
    "arc_chal_val = arc_chal_val.map(\n",
    "    lambda x: {\n",
    "        \"question\": create_questions(x[\"question\"], x[\"choices\"], x[\"answerKey\"])[0],\n",
    "        \"answer\": create_questions(x[\"question\"], x[\"choices\"], x[\"answerKey\"])[1],\n",
    "        \"source\": \"allenai/ai2_arc_challenge\",\n",
    "    },\n",
    "    remove_columns=[\"choices\", \"answerKey\", \"id\"]\n",
    ")\n",
    "arc_chal_test = arc_chal_test.map(\n",
    "    lambda x: {\n",
    "        \"question\": create_questions(x[\"question\"], x[\"choices\"], x[\"answerKey\"])[0],\n",
    "        \"answer\": create_questions(x[\"question\"], x[\"choices\"], x[\"answerKey\"])[1],\n",
    "        \"source\": \"allenai/ai2_arc_challenge\",\n",
    "    },\n",
    "    remove_columns=[\"choices\", \"answerKey\", \"id\"]   \n",
    ")\n",
    "arc_easy_val = arc_easy_val.map(\n",
    "    lambda x: {\n",
    "        \"question\": create_questions(x[\"question\"], x[\"choices\"], x[\"answerKey\"])[0],\n",
    "        \"answer\": create_questions(x[\"question\"], x[\"choices\"], x[\"answerKey\"])[1],\n",
    "        \"source\": \"allenai/ai2_arc_easy\",\n",
    "    },\n",
    "    remove_columns=[\"choices\", \"answerKey\", \"id\"]\n",
    ")\n",
    "arc_easy_test = arc_eady_test.map(\n",
    "    lambda x: {\n",
    "        \"question\": create_questions(x[\"question\"], x[\"choices\"], x[\"answerKey\"])[0],\n",
    "        \"answer\": create_questions(x[\"question\"], x[\"choices\"], x[\"answerKey\"])[1],\n",
    "        \"source\": \"allenai/ai2_arc_easy\",\n",
    "    },\n",
    "    remove_columns=[\"choices\", \"answerKey\", \"id\"]\n",
    ")\n",
    "arc_chal_train = arc_chal_train.map(\n",
    "    lambda x: {\n",
    "        \"question\": create_questions(x[\"question\"], x[\"choices\"], x[\"answerKey\"])[0],\n",
    "        \"answer\": create_questions(x[\"question\"], x[\"choices\"], x[\"answerKey\"])[1],\n",
    "        \"source\": \"allenai/ai2_arc_challenge\",\n",
    "    },\n",
    "    remove_columns=[\"choices\", \"answerKey\", \"id\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4907da",
   "metadata": {},
   "source": [
    "# Med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9c65cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_val = load_dataset(\"openlifescienceai/medmcqa\")[\"validation\"]\n",
    "med_train = load_dataset(\"openlifescienceai/medmcqa\")[\"train\"]\n",
    "med_val = med_val.filter(lambda x: x[\"choice_type\"] == \"single\")\n",
    "med_train = med_train.filter(lambda x: x[\"choice_type\"] == \"single\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "30c954d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee426809c91e441f9f676478fe8ef285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120765 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_question_med(question, options, correct_index, shuffle=True):\n",
    "    if options is None or len(options) == 0:\n",
    "        return question\n",
    "    if shuffle:\n",
    "        random.shuffle(options)\n",
    "    correct_option = options[correct_index]\n",
    "    correct_answer = f\"{chr(65 + correct_index)}. {correct_option}\"\n",
    "    for i, option in enumerate(options):\n",
    "        question += f\"\\n{chr(65 + i)}. {option}\"\n",
    "    return question, correct_answer\n",
    "\n",
    "med_val = med_val.map(\n",
    "    lambda x: {\n",
    "        \"question\": (created_question := create_question_med(\n",
    "            x[\"question\"], \n",
    "            [x[\"opa\"], x[\"opb\"], x[\"opc\"], x[\"opd\"]], \n",
    "            x[\"cop\"]))[0],\n",
    "        \"answer\": created_question[1],\n",
    "        \"source\": \"openlifescienceai/medmcqa\",\n",
    "    },\n",
    "    remove_columns=[col for col in med_val.column_names if col not in [\"question\", \"answer\", \"source\"]]\n",
    ")\n",
    "med_train = med_train.map(\n",
    "    lambda x: {\n",
    "        \"question\": (created_question := create_question_med(\n",
    "            x[\"question\"], \n",
    "            [x[\"opa\"], x[\"opb\"], x[\"opc\"], x[\"opd\"]], \n",
    "            x[\"cop\"]))[0],\n",
    "        \"answer\": created_question[1],\n",
    "        \"source\": \"openlifescienceai/medmcqa\",\n",
    "    },\n",
    "    remove_columns=[col for col in med_train.column_names if col not in [\"question\", \"answer\", \"source\"]]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef03085",
   "metadata": {},
   "source": [
    "# Sciq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "609672ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'source'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"allenai/sciq\")\n",
    "sciq_test = dataset[\"test\"]\n",
    "sciq_val = dataset[\"validation\"]\n",
    "sciq_train = dataset[\"train\"]\n",
    "def create_question(question, options, shuffle=True):\n",
    "    if options is None or len(options) == 0:\n",
    "        return question\n",
    "    correct_option = options[0]\n",
    "    if shuffle:\n",
    "        random.shuffle(options)\n",
    "    correct_index = options.index(correct_option)\n",
    "    correct_answer = f\"{chr(65 + correct_index)}. {correct_option}\"\n",
    "    for i, option in enumerate(options):\n",
    "        question += f\"\\n{chr(65 + i)}. {option}\"\n",
    "    return question, correct_answer\n",
    "\n",
    "# Map the dataset to only keep two columns: question and correct answer\n",
    "sciq_val = sciq_val.map(\n",
    "    lambda x: \n",
    "    {\n",
    "        \"question\": (created_question := create_question(x[\"question\"], [x[\"correct_answer\"], x[\"distractor1\"], x[\"distractor2\"], x[\"distractor3\"]], shuffle=True))[0],\n",
    "        \"answer\": created_question[1],\n",
    "        \"source\": \"allenai/sciq\",\n",
    "    },\n",
    "    remove_columns=sciq_val.column_names\n",
    ")\n",
    "\n",
    "sciq_test = sciq_test.map(\n",
    "    lambda x: \n",
    "    {\n",
    "        \"question\": (created_question := create_question(x[\"question\"], [x[\"correct_answer\"], x[\"distractor1\"], x[\"distractor2\"], x[\"distractor3\"]], shuffle=True))[0],\n",
    "        \"answer\": created_question[1],\n",
    "        \"source\": \"allenai/sciq\",\n",
    "    },\n",
    "    remove_columns=sciq_test.column_names\n",
    ")\n",
    "sciq_train = sciq_train.map(\n",
    "    lambda x: \n",
    "    {\n",
    "        \"question\": (created_question := create_question(x[\"question\"], [x[\"correct_answer\"], x[\"distractor1\"], x[\"distractor2\"], x[\"distractor3\"]], shuffle=True))[0],\n",
    "        \"answer\": created_question[1],\n",
    "        \"source\": \"allenai/sciq\",\n",
    "    },\n",
    "    remove_columns=sciq_train.column_names\n",
    ")\n",
    "sciq_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46cf756",
   "metadata": {},
   "source": [
    "# MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "adbf09bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'source'],\n",
       "    num_rows: 271\n",
       "})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu = load_dataset(\"cais/mmlu\", \"all\")\n",
    "mmlu_stem_subjects = [\n",
    "    \"abstract_algebra\",\n",
    "    \"anatomy\",\n",
    "    \"college_biology\",\n",
    "    \"college_chemistry\",\n",
    "    \"college_computer_science\",\n",
    "    \"college_mathematics\",\n",
    "    \"college_physics\",\n",
    "    \"electrical_engineering\",\n",
    "    \"elementary_mathematics\",\n",
    "    \"high_school_biology\",\n",
    "    \"high_school_chemistry\",\n",
    "    \"high_school_computer_science\",\n",
    "    \"high_school_mathematics\",\n",
    "    \"high_school_physics\",\n",
    "    \"high_school_statistics\"\n",
    "]\n",
    "mmlu_train = mmlu[\"auxiliary_train\"]\n",
    "mmlu = mmlu.filter(lambda x: x[\"subject\"] in mmlu_stem_subjects)\n",
    "mmlu_val = mmlu[\"validation\"]\n",
    "mmlu_test = mmlu[\"test\"]\n",
    "\n",
    "def create_mmlu_question(question, options, index):\n",
    "    formatted_question = question\n",
    "    for i, option in enumerate(options):\n",
    "        formatted_question += f\"\\n{chr(65 + i)}. {option}\"\n",
    "    \n",
    "    # Get the correct answer option (A, B, C, etc.)\n",
    "    answer_letter = chr(65 + index)  \n",
    "    answer_text = f\"{answer_letter}. {options[index]}\"\n",
    "    \n",
    "    return formatted_question, answer_text\n",
    "\n",
    "\n",
    "mmlu_val = mmlu_val.map(\n",
    "    lambda x: {\n",
    "        \"question\": create_mmlu_question(x[\"question\"], x[\"choices\"], x[\"answer\"])[0],\n",
    "        \"response\": create_mmlu_question(x[\"question\"], x[\"choices\"], x[\"answer\"])[1],\n",
    "        \"source\": \"cais/mmlu\",\n",
    "    },\n",
    "    remove_columns=mmlu_val.column_names\n",
    ")\n",
    "\n",
    "mmlu_test = mmlu_test.map(\n",
    "    lambda x: {\n",
    "        \"question\": create_mmlu_question(x[\"question\"], x[\"choices\"], x[\"answer\"])[0],\n",
    "        \"response\": create_mmlu_question(x[\"question\"], x[\"choices\"], x[\"answer\"])[1],\n",
    "        \"source\": \"cais/mmlu\",\n",
    "    },\n",
    "    remove_columns=mmlu_test.column_names\n",
    ")\n",
    "mmlu_train = mmlu_train.map(\n",
    "    lambda x: {\n",
    "        \"question\": create_mmlu_question(x[\"question\"], x[\"choices\"], x[\"answer\"])[0],\n",
    "        \"response\": create_mmlu_question(x[\"question\"], x[\"choices\"], x[\"answer\"])[1],\n",
    "        \"source\": \"cais/mmlu\",\n",
    "    },\n",
    "    remove_columns=mmlu_train.column_names\n",
    ")\n",
    "mmlu_train = mmlu_train.rename_column(\"response\", \"answer\")\n",
    "mmlu_val = mmlu_val.rename_column(\"response\", \"answer\")\n",
    "mmlu_test = mmlu_test.rename_column(\"response\", \"answer\")\n",
    "mmlu_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b4ef9601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'source'],\n",
       "    num_rows: 2554\n",
       "})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61214c3",
   "metadata": {},
   "source": [
    "# M1 prefrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36918204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea99e3605994979aa30e930756428e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'In JOS, suppose a value is passed between two Envs. What is the minimum number of executed system calls?\\nA. 1\\nB. 3\\nC. 4', 'answer': 'B. 3', 'source': 'm1_preference_data'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'source'],\n",
       "    num_rows: 450\n",
       "})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../../data/m1_preference_data.json\") as f:\n",
    "    m1_data = json.load(f)\n",
    "\n",
    "dataset = {\n",
    "    \"question\": [],\n",
    "    \"answer\": [],\n",
    "    \"source\": []\n",
    "}\n",
    "\n",
    "for qst in m1_data:\n",
    "    if qst[\"question_type\"] == \"mcq\":\n",
    "        question_body = qst[\"question_body\"]\n",
    "        options = qst[\"question_options\"]\n",
    "        correct_answer = qst[\"question_answer\"]\n",
    "        if correct_answer[0] == \"[\":\n",
    "            correct_answer = eval(correct_answer)\n",
    "            correct_answer = correct_answer[0]\n",
    "            options = [opt for opt in options if opt not in correct_answer]\n",
    "        if isinstance(correct_answer, int):\n",
    "            correct_answer = options[correct_answer -1]\n",
    "        if isinstance(correct_answer, str) and correct_answer.isdigit():\n",
    "            if int(correct_answer) > 0 and int(correct_answer) <= len(options):\n",
    "                correct_answer = options[int(correct_answer) - 1]\n",
    "        for i, option in enumerate(options):\n",
    "            if correct_answer in option:\n",
    "                correct_answer = chr(65 + i) + \". \" + option\n",
    "                question = question_body + \"\\n\" + \"\\n\".join([chr(65 + i) + \". \" + opt for i, opt in enumerate(options)])\n",
    "                dataset[\"question\"].append(question)\n",
    "                dataset[\"answer\"].append(correct_answer)\n",
    "                dataset[\"source\"].append(\"m1_preference_data\")\n",
    "                break\n",
    "\n",
    "\n",
    "len(dataset[\"question\"]), len(dataset[\"answer\"]), len(dataset[\"source\"])\n",
    "dataset_formatted = Dataset.from_dict(dataset)\n",
    "m1_dataset = dataset_formatted.map(\n",
    "    lambda x: {\n",
    "        \"question\": x[\"question\"],\n",
    "        \"answer\": x[\"answer\"],\n",
    "        \"source\": x[\"source\"],\n",
    "    },\n",
    "    remove_columns=[\"question\", \"answer\", \"source\"]\n",
    ")\n",
    "print(m1_dataset[0])  # Display the first formatted question and answer\n",
    "m1_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b08cbea",
   "metadata": {},
   "source": [
    "# MMLU-PRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "94a028c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'source'],\n",
       "    num_rows: 70\n",
       "})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu_pro_test = load_dataset(\"TIGER-Lab/MMLU-Pro\")[\"test\"]\n",
    "mmlu_pro_val = load_dataset(\"TIGER-Lab/MMLU-Pro\")[\"validation\"]\n",
    "\n",
    "def create_mmlu_pro_question(question, options, index):\n",
    "    letters = [chr(65 + i) for i in range(len(options))]\n",
    "    formatted_question = question\n",
    "    for i, option in enumerate(options):\n",
    "        formatted_question += f\"\\n{letters[i]}. {option}\"\n",
    "    answer_letter = letters[index]\n",
    "    answer_text = f\"{answer_letter}. {options[index]}\"\n",
    "    return formatted_question, answer_text\n",
    "\n",
    "mmlu_pro_val = mmlu_pro_val.map(\n",
    "    lambda x: {\n",
    "        \"question\": create_mmlu_pro_question(x[\"question\"], x[\"options\"], x[\"answer_index\"])[0],\n",
    "        \"answer\": create_mmlu_pro_question(x[\"question\"], x[\"options\"], x[\"answer_index\"])[1],\n",
    "        \"source\": \"TIGER-Lab/MMLU-Pro\",\n",
    "    },\n",
    "    remove_columns=mmlu_pro_val.column_names\n",
    ")\n",
    "mmlu_pro_test = mmlu_pro_test.map(\n",
    "    lambda x: {\n",
    "        \"question\": create_mmlu_pro_question(x[\"question\"], x[\"options\"], x[\"answer_index\"])[0],\n",
    "        \"answer\": create_mmlu_pro_question(x[\"question\"], x[\"options\"], x[\"answer_index\"])[1],\n",
    "        \"source\": \"TIGER-Lab/MMLU-Pro\",\n",
    "    },\n",
    "    remove_columns=mmlu_pro_test.column_names\n",
    ")\n",
    "\n",
    "mmlu_pro_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e09f2265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'source'],\n",
      "    num_rows: 97467\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'source'],\n",
      "    num_rows: 1119\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'source'],\n",
      "    num_rows: 120765\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'source'],\n",
      "    num_rows: 11679\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'source'],\n",
      "    num_rows: 99842\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "for ds in [    aquarat_train,\n",
    "    arc_chal_train,\n",
    "    med_train,\n",
    "    sciq_train,\n",
    "    mmlu_train]:\n",
    "    print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038c3edd",
   "metadata": {},
   "source": [
    "# Merge all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "488ceb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = concatenate_datasets([\n",
    "    aquarat_validation,\n",
    "    arc_chal_val,\n",
    "    arc_easy_val,\n",
    "    med_val,\n",
    "    sciq_val,\n",
    "    mmlu_val,\n",
    "    mmlu_pro_val\n",
    "])\n",
    "\n",
    "test_dataset = concatenate_datasets([\n",
    "    aquarat_test,\n",
    "    arc_chal_test,\n",
    "    arc_easy_test,\n",
    "    sciq_test,\n",
    "    mmlu_test,\n",
    "    mmlu_pro_test\n",
    "])\n",
    "\n",
    "train_dataset = concatenate_datasets([\n",
    "    aquarat_train,\n",
    "    arc_chal_train,\n",
    "    med_train,\n",
    "    sciq_train,\n",
    "    mmlu_train,\n",
    "    m1_dataset\n",
    "])\n",
    "validation_dataset = validation_dataset.shuffle(seed=42)\n",
    "test_dataset = test_dataset.shuffle(seed=42)\n",
    "train_dataset = train_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1275fb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'source'],\n",
       "    num_rows: 5280\n",
       "})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "441c80f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'source'],\n",
       "    num_rows: 19388\n",
       "})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5270dcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'source'],\n",
       "    num_rows: 331322\n",
       "})"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "25767c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166266341c5c484a9a5184da6d313adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5280 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074d6de573634967aedecc41d3290af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19388 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'source'],\n",
       "    num_rows: 331322\n",
       "})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"MCQ_prompts.json\") as f:\n",
    "    mcq_prompts = json.load(f)\n",
    "\n",
    "def add_prompts(example):\n",
    "    prompt = random.choice(mcq_prompts)\n",
    "    question = prompt.replace(\"<question>\", example[\"question\"])\n",
    "    example[\"question\"] = question\n",
    "    return example\n",
    "\n",
    "final_train_dataset = train_dataset.map(add_prompts)\n",
    "final_validation_dataset = validation_dataset.map(add_prompts)\n",
    "final_test_dataset = test_dataset.map(add_prompts)\n",
    "final_train_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a797266d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3da2609ce848399ba675bf99471a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7b38b9ed8c416da77efb4e67acfc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/332 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aff0ef0b5d04691aa50a9c51bf750d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8016b5e32f8c4cba9d0d4523f95d9307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203d34bf15c64c86a192b15198c0568b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f591654f50f74a6e83917dd6f30fe472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/HAissa/MCQ_dataset/commit/a4a0d29bfbd858f41959fc2e5368224ca26ea482', commit_message='Upload dataset', commit_description='', oid='a4a0d29bfbd858f41959fc2e5368224ca26ea482', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/HAissa/MCQ_dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='HAissa/MCQ_dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_dataset = DatasetDict({\n",
    "    \"train\": final_train_dataset,\n",
    "    \"validation\": final_validation_dataset,\n",
    "    \"test\": final_test_dataset,\n",
    "})\n",
    "complete_dataset.push_to_hub(\"HAissa/MCQ_dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
